{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "roll_number = re.compile(r'([1,2][0,5,6,7,8,9].\\d*)|tezansahu')\n",
    "\n",
    "class Post(object):\n",
    "    def __init__(self,author,subject,raw_text):\n",
    "#         print(author,subject)\n",
    "        self.author = re.findall(roll_number,author)[0]\n",
    "        self.subject = re.findall(roll_number,subject)[0]\n",
    "        self.raw_text = raw_text\n",
    "        self.text,self.mentions = self.get_text_mentions(raw_text)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.author} wrote the following about {self.subject} : \\n {self.text}\"\n",
    " \n",
    "    def get_text_mentions(self,raw_text):\n",
    "        # TODO\n",
    "        return raw_text, None\n",
    "    def asdict(self):\n",
    "        return {\"Author\":self.author,\"Subject\":self.subject,\"Text\":self.text}\n",
    "\n",
    "\n",
    "class Person(object):\n",
    "    def __init__(self,id,name,degree,dept,hostel,ibs):\n",
    "        self.id = re.findall(roll_number,id)[0]\n",
    "        self.name = name\n",
    "        self.degree = degree\n",
    "        self.dept = dept\n",
    "        self.hostel = hostel\n",
    "        self.ibs = ibs   # TODO see how to put into sql\n",
    "        self.posts_auth = []\n",
    "        self.posts_subj = []\n",
    "        self.posts_tagged = []\n",
    "    def __str__(self):\n",
    "        \n",
    "        ibs_str = \", \".join(list(self.ibs))\n",
    "        return f\"Name: {self.name}, Program: {self.degree}, Dept: {self.dept}, Hostel: {self.hostel}, Clubs Associated with: {ibs_str}\"\n",
    "    \n",
    "    def compute_post_stats(self):\n",
    "        self.auth_len = np.mean([len(x.text.split()) for x in self.posts_auth])\n",
    "        self.subj_len = np.mean([len(x.text.split()) for x in self.posts_subj])\n",
    "        \n",
    "    def asdict(self):\n",
    "        return {\"Name\":self.name,\"id\":self.id,\"Degree\":self.degree,\"Department\":self.dept,\"Hostel\":self.hostel,\n",
    "                \"IBs\":self.ibs,\"Gender\":self.gender, \"Posts Auth\":[x.asdict() for x in self.posts_auth],\n",
    "                \"Posts Subj\":[x.asdict() for x in self.posts_subj]\n",
    "               ,\"Posts Tagged\":[x.asdict() for x in self.posts_tagged]}\n",
    "\n",
    "def get_gender(name):\n",
    "    if name.lstrip().startswith(\"Ms.\"):\n",
    "        # print(\"Girl\")\n",
    "        return \"Female\"\n",
    "    else:\n",
    "        return \"Male\"\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "def get_pers(page,url):\n",
    "    page = soup(page,\"html.parser\")\n",
    "    personal_info = page.find(\"ul\",class_=\"list-unstyled puser-details-list\").find('li')\n",
    "\n",
    "    name = personal_info.find('h2').text.split('\\n')[0]\n",
    "    # print(name)\n",
    "    dets = personal_info.find_all('h5')#.text\n",
    "\n",
    "    try:\n",
    "        degree,dept,hostel = dets[0].text.split('|')\n",
    "    except:\n",
    "        degree,dept,hostel = None,None,None\n",
    "    try:\n",
    "        ibs = (dets[1].text.split('|'))\n",
    "    except:\n",
    "        ibs = []\n",
    "\n",
    "    new_pers = Person(url,name,degree,dept,hostel,ibs)\n",
    "\n",
    "    incoming_edges = page.find(\"div\",id=\"myTabContent\").find_all(\"div\",class_=\"sub-post-container\")\n",
    "    # print(len(incoming_edges))\n",
    "    for post in incoming_edges:\n",
    "        parent = post.find_parent('div')\n",
    "        if \"tab-pane\" not in parent[\"class\"] or \"impression\" in parent[\"id\"]:\n",
    "            # This is done to make sure that only posts are taken in\n",
    "            continue\n",
    "        author = post.find(\"div\",class_=\"user-details\").find(\"a\")\n",
    "        author_id = author['href']\n",
    "        author_name = author.text  # This is not strictly necessary, keeping it for now\n",
    "        subject = author.find_next(\"div\",class_=\"user-details\").find(\"a\")\n",
    "        subject_id = subject['href']\n",
    "        subject_name = subject.text\n",
    "\n",
    "        post_text = post.find(\"p\",class_=\"post-para\").text\n",
    "        new_post = Post(author_id,subject_id,post_text)\n",
    "        if new_pers.id == new_post.subject:  # Handle the case of two people with the same name\n",
    "            new_pers.posts_subj.append(new_post)\n",
    "        elif new_pers.id == new_post.author:\n",
    "            new_pers.posts_auth.append(new_post)\n",
    "\n",
    "        else:   # Need to handle mentions separae\n",
    "            new_pers.posts_tagged.append(new_post)\n",
    "\n",
    "    new_pers.compute_post_stats()\n",
    "    return new_pers\n",
    "# print(new_pers.auth_len,new_pers.subj_len)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# In this cell I try to get the roll numbers of everyone from the xlsx\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json \n",
    "\n",
    "df = pd.read_excel('roll_list.xls',header=None)\n",
    "roll_numbers = df.loc[:,1]\n",
    "names = df.loc[:,2]\n",
    "all_people = {}\n",
    "for idx,roll in (enumerate(roll_numbers)):\n",
    "#     if idx < 730:\n",
    "#         continue\n",
    "\n",
    "    try:\n",
    "        roll = str(roll).strip()\n",
    "        url = f\"https://yearbook.sarc-iitb.org/student-{roll}/\"\n",
    "        # csrftoken = \"LtXF0VdvU6UlShr5CPjbFdKQaFAoUt5C32GQaoIj1q0BmypIUPqH1WhP2wznt591\"\n",
    "        # cookies = dict(_ga_QHYLVSRXM2=\"GS1.1.1624347864.32.1.1624348240.0\", _ga=\"GA1.1.793406901.1620407148\", csrftoken=csrftoken, sessionid=\"uzeibeb0ggqa6zpilm4j9d332yicw00m\")\n",
    "        # page = requests.get(url,cookies=cookies)\n",
    "        # print(roll)\n",
    "        page = open(f\"raw_data_sunday/{roll}.html\",\"r\").read()\n",
    "        # file = open(f\"raw_data_sunday/{roll}.html\",\"w\")\n",
    "        # file.write(page.text)\n",
    "        # file.close()\n",
    "        # pers = get_pers(page.text,url)\n",
    "        pers = get_pers(page,url)\n",
    "        pers.gender = get_gender(names[idx])\n",
    "        all_people[roll] = (pers.asdict())\n",
    "#         file = open(\"raw_data.jsonl\",\"a\")\n",
    "#         print(json.dumps(pers.asdict()),file=file)\n",
    "#         file.close()\n",
    "    except Exception as e: \n",
    "        print(f\"Skipping {roll} because {e}\")\n",
    "        break\n",
    "\n",
    "json.dump(all_people,open(\"raw_data_latest.json\",\"w\"))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Skipping 170100035 because 'NoneType' object has no attribute 'find'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# !pip uninstall -y beautifulsoup4\n",
    "!pip install beautifulsoup4 == 4.8.0\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting beautifulsoup4==4.8.0\n",
      "  Downloading beautifulsoup4-4.8.0-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 3.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: soupsieve>=1.2 in /home/codespace/.local/lib/python3.8/site-packages (from beautifulsoup4==4.8.0) (2.2.1)\n",
      "Installing collected packages: beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.8.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "!mkdir raw_data_sunday"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mkdir: cannot create directory ‘raw_data_sunday’: File exists\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "!pip uninstall -y bs4"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing installation: bs4 0.0.1\n",
      "Uninstalling bs4-0.0.1:\n",
      "  Successfully uninstalled bs4-0.0.1\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}